{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train_googlenet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"markdown","metadata":{"id":"e-BWyHS3s82p"},"source":["# **Train the output layer of MobileNet-v2**"]},{"cell_type":"markdown","metadata":{"id":"zNRgZ-ZwtONW"},"source":["**Train the output layer of MobileNet-v2 for mask detection**"]},{"cell_type":"markdown","metadata":{"id":"tADR3awCtJ5Z"},"source":["### **Start by mounting the drive**"]},{"cell_type":"markdown","metadata":{"id":"JRGcRn2b53Ii"},"source":["**Mounting the Drive allows the notebook to access the dataset folder. You can see all the files in your Drive this way, but no one else can see them because a new VM is loaded each time. **"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uri0sJ-d12kg","outputId":"29eb7a32-adcb-4ff2-f65e-3b49f8660738"},"source":[" from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1MwZry3EtslO"},"source":["### **Load the required modules and data**\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"m6iZwvsPtuQ1"},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","from PIL import Image\n","import torch\n","import torchvision\n","import torch.nn as nn\n","from torchvision import transforms as trn\n","from torch.autograd import Variable as V\n","import torch.nn.functional as F\n","\n","from matplotlib import rcParams\n","rcParams['axes.grid'] = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mm1UqJq92CId","outputId":"002f78af-7f90-4316-d98b-95869e2f36b9"},"source":["# data_path = 'gdrive/My Drive/CV-FinalProject/dataset/'\n","data_path = 'gdrive/My Drive/mask_detection/dataset/'\n","training = pd.read_csv((data_path + 'training/training.csv'), index_col=0)\n","validation = pd.read_csv((data_path + 'validation/validation.csv'), index_col=0)\n","validation.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(200, 2)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"aCvyB-lQ2uzQ"},"source":["### **Preprocess Images**"]},{"cell_type":"code","metadata":{"id":"8Kc0sn0r4UH7"},"source":["def preprocess(image_fname):\n","    center_crop = trn.Compose([\n","        trn.Resize((256, 256)),\n","        trn.CenterCrop(224),\n","        trn.ToTensor(),\n","        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","    img_input = Image.open(image_fname)\n","    return V(center_crop(img_input).unsqueeze(0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIOHWGYp2vTc"},"source":["def batch(df, path, batch_size):\n","  \"\"\"Create a batch of examples.\n","  \n","  This creates a batch of input images and a batch of corresponding\n","  ground-truth labels. We assume CUDA is available (with a GPU).\n","  \n","  Args:\n","    batch_size: An integer.\n","  \n","  Returns:\n","    A tuple,\n","    input_batch: A Variable of floats with shape\n","      [batch_size, 1, height, width]\n","    label_batch: A Variable of ints with shape\n","      [batch_size].\n","  \"\"\"\n","  random_ind = np.random.choice(len(df), size=batch_size, replace=False)\n","  label_batch = df['labels'].iloc[random_ind].to_numpy()\n","\n","  input_batch = preprocess((path + df['files'].iloc[random_ind[0]]))\n","  for i in df['files'].iloc[random_ind[1:]]:\n","      input_batch = torch.cat((input_batch, preprocess((path + i))), 0)\n","  \n","  with torch.no_grad():\n","    input_batch = input_batch.cuda()\n","    label_batch = V(torch.from_numpy(label_batch).cuda())\n","\n","  return input_batch, label_batch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4aa4Bmg4tjls"},"source":["### **Define model**"]},{"cell_type":"markdown","metadata":{"id":"dZdblWqUjfHA"},"source":["**First we are going to load the pretrained model and freeze all the weights. Then, we replace the fully connected output layer with a new layer that will train.**"]},{"cell_type":"code","metadata":{"id":"BK8p9Chus8Ns"},"source":["#load model\n","model = torchvision.models.googlenet(pretrained=True)\n","#print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1VjGMgGAlM55"},"source":["**freeze network layers**\n","https://discuss.pytorch.org/t/how-the-pytorch-freeze-network-in-some-layers-only-the-rest-of-the-training/7088"]},{"cell_type":"code","metadata":{"id":"eZY_TB46lNPb"},"source":["for param in model.parameters():\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4VrFdtNcicMj"},"source":["**replace output layer**\n","https://discuss.pytorch.org/t/how-to-replace-a-layer-or-module-in-a-pretrained-network/60068\n","\n","**`in_features` is the same as before. `out_features` becomes 2 because we only have two classes (mask and no mask). It was 1000 because there 1000 object classes in ImageNet which the model was trained on.** \n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Y7400l2wiEWr"},"source":["model.fc = nn.Linear(in_features=1024, out_features=2, bias=True)\n","#print(model)\n","# model.AuxLogits.fc = nn.Linear(768, 2)\n","# model.fc = nn.Linear(2048, 2)\n","# print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lYSRXjvSmE1G"},"source":["**Send to cuda and check that `requires_grad` for my new layer is True**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_RuvDdDoV8D","outputId":"14993196-83f9-464e-c75a-b77661aab3fd"},"source":["#send to GPU\n","assert torch.cuda.is_available()\n","model.cuda()\n","# model.classifier[-1].weight"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GoogLeNet(\n","  (conv1): BasicConv2d(\n","    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (conv2): BasicConv2d(\n","    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (conv3): BasicConv2d(\n","    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception3a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception3b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception4a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4c): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4d): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4e): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception5a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception5b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (aux1): None\n","  (aux2): None\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"3w5gqXOL2fAR"},"source":["optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0LORuAHak0mD"},"source":["## **Train the model**"]},{"cell_type":"markdown","metadata":{"id":"Kns7m-Jb2Xpd"},"source":["**Helper function that performs the forward pass, backpropagation, and then gradient update steps for a single batch.**"]},{"cell_type":"code","metadata":{"id":"_9Ik-KSp2YEp"},"source":["def train_step(batch_size=32):\n","  \n","  model.train()\n","\n","  input_batch, label_batch = batch(training, (data_path + 'training/'), batch_size)\n","  output_batch = model(input_batch)\n","\n","  loss = F.cross_entropy(output_batch, label_batch)\n","  _, pred_batch = torch.max(output_batch, dim=1)\n","  error_rate = 1.0 - (pred_batch == label_batch).float().mean()\n","\n","  optimizer.zero_grad()\n","  loss.backward()\n","  \n","  optimizer.step()\n","  \n","  return loss.data, error_rate.data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M_2VJjrg2isu"},"source":["**Evaluation function**"]},{"cell_type":"code","metadata":{"id":"t5nqcIoaig46"},"source":["def val(input_batch, label_batch):\n","  \n","  model.eval()\n","  \n","  output_batch = model(input_batch)\n","\n","  loss = F.cross_entropy(output_batch, label_batch)\n","  _, pred_batch = torch.max(output_batch, dim=1)\n","  error_rate = 1.0 - (pred_batch == label_batch).float().mean()\n","  \n","  return loss.data, error_rate.data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bdbCZSG1oBd1"},"source":["**Load the validation data**"]},{"cell_type":"code","metadata":{"id":"YoQGBWu8oBp2"},"source":["input_val, label_val = batch(validation, (data_path + 'validation/'), len(validation))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gXA6q2oc2lx-"},"source":["**Finally, let's train, and also plot loss and error rate as a function of iteration.**"]},{"cell_type":"code","metadata":{"id":"YaZQa05-tcwj"},"source":["def test():\n","  data_path = 'gdrive/My Drive/mask_detection/dataset/'\n","  test = pd.read_csv((data_path + 'validation/validation.csv'), index_col=0)\n","  cor = 0\n","  err = 0\n","  for i in range(test.shape[0]):\n","    filename = test.iloc[i, 0]\n","    label = test.iloc[i, 1]\n","\n","    img=preprocess('gdrive/My Drive/mask_detection/dataset/validation/' + filename)\n","    img=img.type(torch.cuda.FloatTensor)\n","    outputs = model(img)\n","    _, predicted = torch.max(outputs, 1)\n","    rlt = predicted[0]\n","    if(rlt == label):\n","      cor += 1.0\n","    else:\n","      err += 1.0\n","  AP = cor / (cor + err)\n","  return AP"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1oaoo06s2l7B","colab":{"base_uri":"https://localhost:8080/","height":439},"outputId":"90b903fc-eb24-4f38-c5e5-4dfbf05b1d7c"},"source":["# info = []\n","# fig, ax = plt.subplots(2, 1, sharex=True)\n","# num_steps = 500\n","# num_steps_per_val = 50\n","# best_val_err = 1.0\n","# for step in range(num_steps):\n","#   train_loss, train_err = train_step()\n","#   if step % num_steps_per_val == 0:\n","#     val_loss, val_err = val(input_val, label_val)\n","#     if val_err < best_val_err:\n","#       best_val_err = val_err\n","#       # print('Step {:5d}: Obtained a best validation error of {:.3f}.'.format(step, best_val_err))\n","#       print('Step {:5d}: Obtained a best validation error of {:.6f}. loss of {:.6f}'.format(step, best_val_err, val_loss))\n","#     else:\n","#       print('Step {:5d}: Obtained a best validation error of {:.6f}. loss of {:.6f}'.format(step, best_val_err, val_loss))\n","#     info.append([step, train_loss, val_loss, train_err, val_err])\n","#     x, y11, y12, y21, y22 = zip(*info)\n","#     ax[0].plot(x, y11, x, y12)\n","#     ax[0].legend(['Train loss', 'Val loss'])\n","#     ax[1].plot(x, y21, x, y22)\n","#     ax[1].legend(['Train err', 'Val err'])\n","#     ax[1].set_ylim([0.0, 0.25])\n","\n","info = []\n","fig, ax = plt.subplots(2, 1, sharex=True)\n","num_steps = 500\n","num_steps_per_val = 50\n","best_val_err = 1.0\n","for step in range(num_steps):\n","  train_loss, train_err = train_step()\n","  if step % num_steps_per_val == 0:\n","    AP = test()\n","    print('Step {:5d}: Obtained a best validation AP of {:.6f}. train loss {:.6f}'.format(step, AP, train_loss))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Step     0: Obtained a best validation AP of 0.515000. train loss 0.696063\n","Step    50: Obtained a best validation AP of 0.535000. train loss 0.207306\n","Step   100: Obtained a best validation AP of 0.530000. train loss 0.105221\n","Step   150: Obtained a best validation AP of 0.510000. train loss 0.110814\n","Step   200: Obtained a best validation AP of 0.525000. train loss 0.070856\n","Step   250: Obtained a best validation AP of 0.510000. train loss 0.116329\n","Step   300: Obtained a best validation AP of 0.530000. train loss 0.115192\n","Step   350: Obtained a best validation AP of 0.515000. train loss 0.051505\n","Step   400: Obtained a best validation AP of 0.530000. train loss 0.060804\n","Step   450: Obtained a best validation AP of 0.500000. train loss 0.027068\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATh0lEQVR4nO3db4xdd33n8fenhiRq6IKpvVJkexPTuk3SbkXgyrBCWlhBEpMHNhLV1qkQDkpricVUgqpSKh5k5TyhRbtUSGmJt7WAShsH8mA11YKsiBBFWmHqa5GmxJVhcFsyLlIGHPIkbLJOvvvgnnSuJ2PP8fh67nh+75d0Nff8zvnd+c5PM/cz5889v1QVkqR2/cK0C5AkTZdBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUuGWDIMnhJM8l+d4F1ifJF5LMJnk6yTvG1u1L8oPusW+ShUuSJqPPHsGXgF0XWf9BYEf32A/8BUCStwL3A+8CdgL3J9l4OcVKkiZv2SCoqieBsxfZZA/wlRo5BrwlyQ3AncBjVXW2qp4HHuPigSJJmoI3TOA1tgDPji3PdW0Xan+dJPsZ7U1w/fXXv/Pmm2+eQFmS1I4TJ078pKo2r6TvJILgslXVIeAQwGAwqOFwOOWKJOnqkuSfV9p3ElcNnQG2jS1v7dou1C5JWkMmEQQzwEe7q4feDbxQVT8GjgJ3JNnYnSS+o2uTJK0hyx4aSvIw8D5gU5I5RlcCvRGgqr4IfB24C5gFXgQ+1q07m+QB4Hj3Uger6mInnSVJU7BsEFTV3cusL+ATF1h3GDi8stIkSavBTxZLUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhrXKwiS7EpyKslskvuWWP/5JE91j+8n+dnYulfG1s1MsnhJ0uXrM1XlBuBB4HZgDjieZKaqTr62TVV9amz7TwK3jb3Ez6vq7ZMrWZI0SX32CHYCs1V1uqpeBo4Aey6y/d3Aw5MoTpJ05fUJgi3As2PLc13b6yS5EdgOPD7WfF2SYZJjST50gX77u22G8/PzPUuXJE3CpE8W7wUerapXxtpurKoB8LvAnyX5lcWdqupQVQ2qarB58+YJlyRJupg+QXAG2Da2vLVrW8peFh0Wqqoz3dfTwBOcf/5AkjRlfYLgOLAjyfYk1zB6s3/d1T9JbgY2At8ea9uY5Nru+SbgPcDJxX0lSdOz7FVDVXUuyQHgKLABOFxVzyQ5CAyr6rVQ2Ascqaoa634L8FCSVxmFzmfHrzaSJE1fzn/fnr7BYFDD4XDaZUjSVSXJie587CXzk8WS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMb1CoIku5KcSjKb5L4l1t+TZD7JU93j98bW7Uvyg+6xb5LFS5Iu37JTVSbZADwI3A7MAceTzCwx5eQjVXVgUd+3AvcDA6CAE13f5ydSvSTpsvXZI9gJzFbV6ap6GTgC7On5+ncCj1XV2e7N/zFg18pKlSRdCX2CYAvw7NjyXNe22IeTPJ3k0STbLqVvkv1JhkmG8/PzPUuXJE3CpE4W/w1wU1X9FqP/+r98KZ2r6lBVDapqsHnz5gmVJEnqo08QnAG2jS1v7dr+VVX9tKpe6hb/Enhn376SpOnqEwTHgR1Jtie5BtgLzIxvkOSGscXdwD90z48CdyTZmGQjcEfXJklaI5a9aqiqziU5wOgNfANwuKqeSXIQGFbVDPAHSXYD54CzwD1d37NJHmAUJgAHq+rsFfg5JEkrlKqadg3nGQwGNRwOp12GJF1VkpyoqsFK+vrJYklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhrXKwiS7EpyKslskvuWWP/pJCe7yeu/meTGsXWvJHmqe8ws7itJmq5lZyhLsgF4ELgdmAOOJ5mpqpNjm30XGFTVi0k+Dvwp8Dvdup9X1dsnXLckaUL67BHsBGar6nRVvQwcAfaMb1BV36qqF7vFY4wmqZckXQX6BMEW4Nmx5bmu7ULuBb4xtnxdkmGSY0k+tFSHJPu7bYbz8/M9SpIkTcqyh4YuRZKPAAPgvWPNN1bVmSRvAx5P8vdV9cPxflV1CDgEozmLJ1mTJOni+uwRnAG2jS1v7drOk+QDwGeA3VX10mvtVXWm+3oaeAK47TLqlSRNWJ8gOA7sSLI9yTXAXuC8q3+S3AY8xCgEnhtr35jk2u75JuA9wPhJZknSlC17aKiqziU5ABwFNgCHq+qZJAeBYVXNAJ8D3gR8LQnAj6pqN3AL8FCSVxmFzmcXXW0kSZqyVK2tQ/KDwaCGw+G0y5Ckq0qSE1U1WElfP1ksSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWpcryBIsivJqSSzSe5bYv21SR7p1n8nyU1j6/64az+V5M7JlS5JmoRlgyDJBuBB4IPArcDdSW5dtNm9wPNV9avA54E/6freymiO498AdgF/3r2eJGmN6LNHsBOYrarTVfUycATYs2ibPcCXu+ePAu/PaPLiPcCRqnqpqv4RmO1eT5K0Riw7eT2wBXh2bHkOeNeFtukmu38B+OWu/diivlsWf4Mk+4H93eJLSb7Xq/r1bxPwk2kXsUY4FgsciwWOxYJfX2nHPkFwxVXVIeAQQJLhSidgXm8ciwWOxQLHYoFjsSDJcKV9+xwaOgNsG1ve2rUtuU2SNwBvBn7as68kaYr6BMFxYEeS7UmuYXTyd2bRNjPAvu75bwOPV1V17Xu7q4q2AzuAv51M6ZKkSVj20FB3zP8AcBTYAByuqmeSHASGVTUD/BXw10lmgbOMwoJuu68CJ4FzwCeq6pVlvuWhlf84645jscCxWOBYLHAsFqx4LDL6x12S1Co/WSxJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDWuz1SVh5M8d6HJYjLyhW5e4qeTvGNs3b4kP+ge+5bqL0marj57BF9iNN/whXyQ0e2ldzCaZewvAJK8Fbif0WxmO4H7k2y8nGIlSZO3bBBU1ZOMbi19IXuAr9TIMeAtSW4A7gQeq6qzVfU88BgXDxRJ0hRMYqrKpeY03nKR9tcZn7P4+uuvf+fNN988gbIkqR0nTpz4SVVtXknfNTdn8WAwqOFwxVNvSlKTkvzzSvtO4qqhC81L7HzFknQVmEQQzAAf7a4eejfwQlX9mNHUlnck2didJL6ja5MkrSHLHhpK8jDwPmBTkjlGVwK9EaCqvgh8HbgLmAVeBD7WrTub5AHgePdSB6vqYiedJUlT0Gfy+ruXWV/AJy6w7jBweGWlSZJWg58slqTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1rlcQJNmV5FSS2ST3LbH+80me6h7fT/KzsXWvjK2bmWTxkqTL12eqyg3Ag8DtwBxwPMlMVZ18bZuq+tTY9p8Ebht7iZ9X1dsnV7IkaZL67BHsBGar6nRVvQwcAfZcZPu7gYcnUZwk6crrEwRbgGfHlue6ttdJciOwHXh8rPm6JMMkx5J86AL99nfbDOfn53uWLkmahEmfLN4LPFpVr4y13VhVA+B3gT9L8iuLO1XVoaoaVNVg8+bNEy5JknQxfYLgDLBtbHlr17aUvSw6LFRVZ7qvp4EnOP/8gSRpyvoEwXFgR5LtSa5h9Gb/uqt/ktwMbAS+Pda2Mcm13fNNwHuAk4v7SpKmZ9mrhqrqXJIDwFFgA3C4qp5JchAYVtVrobAXOFJVNdb9FuChJK8yCp3Pjl9tJEmavpz/vj19g8GghsPhtMuQpKtKkhPd+dhL5ieLJalxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJalyvIEiyK8mpJLNJ7lti/T1J5pM81T1+b2zdviQ/6B77Jlm8JOnyLTtDWZINwIPA7cAccDzJzBIzjT1SVQcW9X0rcD8wAAo40fV9fiLVS5IuW589gp3AbFWdrqqXgSPAnp6vfyfwWFWd7d78HwN2raxUSdKV0CcItgDPji3PdW2LfTjJ00keTbLtUvom2Z9kmGQ4Pz/fs3RJ0iRM6mTx3wA3VdVvMfqv/8uX0rmqDlXVoKoGmzdvnlBJkqQ++gTBGWDb2PLWru1fVdVPq+qlbvEvgXf27StJmq4+QXAc2JFke5JrgL3AzPgGSW4YW9wN/EP3/ChwR5KNSTYCd3RtkqQ1YtmrhqrqXJIDjN7ANwCHq+qZJAeBYVXNAH+QZDdwDjgL3NP1PZvkAUZhAnCwqs5egZ9DkrRCqapp13CewWBQw+Fw2mVI0lUlyYmqGqykr58slqTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1rlcQJNmV5FSS2ST3LbH+00lOJnk6yTeT3Di27pUkT3WPmcV9JUnTtexUlUk2AA8CtwNzwPEkM1V1cmyz7wKDqnoxyceBPwV+p1v386p6+4TrliRNSJ89gp3AbFWdrqqXgSPAnvENqupbVfVit3gM2DrZMiVJV0qfINgCPDu2PNe1Xci9wDfGlq9LMkxyLMmHluqQZH+3zXB+fr5HSZKkSVn20NClSPIRYAC8d6z5xqo6k+RtwONJ/r6qfjjer6oOAYdgNHn9JGuSJF1cnz2CM8C2seWtXdt5knwA+Aywu6peeq29qs50X08DTwC3XUa9kqQJ6xMEx4EdSbYnuQbYC5x39U+S24CHGIXAc2PtG5Nc2z3fBLwHGD/JLEmasmUPDVXVuSQHgKPABuBwVT2T5CAwrKoZ4HPAm4CvJQH4UVXtBm4BHkryKqPQ+eyiq40kSVOWqrV1SH4wGNRwOJx2GZJ0VUlyoqoGK+nrJ4slqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY3rFQRJdiU5lWQ2yX1LrL82ySPd+u8kuWls3R937aeS3Dm50iVJk7BsECTZADwIfBC4Fbg7ya2LNrsXeL6qfhX4PPAnXd9bGc1x/BvALuDPu9eTJK0RffYIdgKzVXW6ql4GjgB7Fm2zB/hy9/xR4P0ZTV68BzhSVS9V1T8Cs93rSZLWiGUnrwe2AM+OLc8B77rQNt1k9y8Av9y1H1vUd8vib5BkP7C/W3wpyfd6Vb/+bQJ+Mu0i1gjHYoFjscCxWPDrK+3YJwiuuKo6BBwCSDJc6QTM641jscCxWOBYLHAsFiQZrrRvn0NDZ4BtY8tbu7Ylt0nyBuDNwE979pUkTVGfIDgO7EiyPck1jE7+zizaZgbY1z3/beDxqqqufW93VdF2YAfwt5MpXZI0CcseGuqO+R8AjgIbgMNV9UySg8CwqmaAvwL+OskscJZRWNBt91XgJHAO+ERVvbLMtzy08h9n3XEsFjgWCxyLBY7FghWPRUb/uEuSWuUniyWpcQaBJDVuakFwObetWG96jMWnk5xM8nSSbya5cRp1roblxmJsuw8nqSTr9tLBPmOR5D93vxvPJPmfq13jaunxN/LvknwryXe7v5O7plHnlZbkcJLnLvRZq4x8oRunp5O8o9cLV9WqPxiddP4h8DbgGuDvgFsXbfNfgC92z/cCj0yj1jUyFv8J+MXu+cdbHotuu18CnmT0YcXBtOue4u/FDuC7wMZu+d9Ou+4pjsUh4OPd81uBf5p23VdoLP4j8A7gexdYfxfwDSDAu4Hv9Hndae0RXM5tK9abZceiqr5VVS92i8cYfR5jPerzewHwAKP7Wf3f1SxulfUZi98HHqyq5wGq6rlVrnG19BmLAv5N9/zNwL+sYn2rpqqeZHRl5oXsAb5SI8eAtyS5YbnXnVYQLHXbisW3njjvthXAa7etWG/6jMW4exkl/nq07Fh0u7rbqup/r2ZhU9Dn9+LXgF9L8n+SHEuya9WqW119xuK/Ah9JMgd8Hfjk6pS25lzq+wmwRm4xoX6SfAQYAO+ddi3TkOQXgP8O3DPlUtaKNzA6PPQ+RnuJTyb591X1s6lWNR13A1+qqv+W5D8w+lzTb1bVq9Mu7GowrT2Cy7ltxXrT6zYcST4AfAbYXVUvrVJtq225sfgl4DeBJ5L8E6NjoDPr9IRxn9+LOWCmqv5fje7u+31GwbDe9BmLe4GvAlTVt4HrGN2QrjUruq3PtILgcm5bsd4sOxZJbgMeYhQC6/U4MCwzFlX1QlVtqqqbquomRudLdlfVim+2tYb1+Rv5X4z2BkiyidGhotOrWeQq6TMWPwLeD5DkFkZBML+qVa4NM8BHu6uH3g28UFU/Xq7TVA4N1WXctmK96TkWnwPeBHytO1/+o6raPbWir5CeY9GEnmNxFLgjyUngFeCPqmrd7TX3HIs/BP5Hkk8xOnF8z3r8xzHJw4zCf1N3PuR+4I0AVfVFRudH7mI098uLwMd6ve46HCtJ0iXwk8WS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXu/wP9fhgdf3R4DAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"VmdvAffNGRvR"},"source":["**Save the learned model weights**"]},{"cell_type":"code","metadata":{"id":"VtWQ94zmlneX"},"source":["# torch.save(model.state_dict(), 'gdrive/My Drive/mask_detection/googlnet_masknet.pth')\n","torch.save(model, 'gdrive/My Drive/mask_detection/googlenet_masknet.pth') "],"execution_count":null,"outputs":[]}]}